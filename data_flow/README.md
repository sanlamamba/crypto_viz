# ğŸª™ **CryptoViz : Surveillez les Cryptomonnaies en Temps RÃ©el** ğŸš€

Bienvenue dans **CryptoViz**, votre solution tout-en-un pour la collecte, le traitement et la visualisation des donnÃ©es de cryptomonnaies. Que vous soyez un passionnÃ© de crypto, un analyste de donnÃ©es ou un dÃ©veloppeur curieux de l'univers des cryptomonnaies, ce projet est fait pour vous ! ğŸ’¡

---

## ğŸŒŸ **FonctionnalitÃ©s Principales**

- **Scraping en Temps RÃ©el :**
  - Collectez des donnÃ©es en temps rÃ©el depuis des sources fiables telles que **CoinGecko** et **CoinMarketCap**.
  - Extrayez des informations comme les prix, les capitalisations boursiÃ¨res, et plus encore. ğŸ“Š

- **Traitement et Validation des DonnÃ©es :**
  - Normalisez les donnÃ©es pour garantir leur cohÃ©rence et Ã©vitez les doublons.
  - Validez les donnÃ©es collectÃ©es pour assurer leur prÃ©cision. âœ…

- **IntÃ©gration Kafka :**
  - GÃ©rez les flux de donnÃ©es en temps rÃ©el avec **Apache Kafka** en tant que producteur/consommateur.
  - Architecture basÃ©e sur des microservices pour une meilleure scalabilitÃ©. âš¡

- **Base de DonnÃ©es PostgreSQL :**
  - Stockez les donnÃ©es en temps rÃ©el et les donnÃ©es historiques dans une base de donnÃ©es relationnelle.
  - Utilisez des migrations **Alembic** pour maintenir la structure de la base Ã  jour. ğŸ“‚

- **Visualisation des DonnÃ©es :**
  - IntÃ©gration prÃªte avec **Grafana** pour crÃ©er des tableaux de bord visuels en temps rÃ©el. ğŸ“ˆ

- **Planification et Multithreading :**
  - ExÃ©cutez des tÃ¢ches Ã  intervalles rÃ©guliers grÃ¢ce au **scheduler**.
  - **Multithreading** pour exÃ©cuter plusieurs tÃ¢ches simultanÃ©ment, optimisant ainsi la performance. ğŸ•’

---

## ğŸ› ï¸ **Structure du Projet**

Le projet est organisÃ© de maniÃ¨re claire pour faciliter la comprÃ©hension et la collaboration. Voici un aperÃ§u :

```
/data_flow/
â”œâ”€â”€ README.md               # Documentation principale
â”œâ”€â”€ docker-compose.yml      # Configuration des services Docker (Kafka, PostgreSQL, Grafana)
â”œâ”€â”€ requirements.txt        # Liste des dÃ©pendances Python
â”œâ”€â”€ src/                    # Code source principal
â”‚   â”œâ”€â”€ scrapers/           # Scripts pour extraire les donnÃ©es de CoinGecko et CoinMarketCap
â”‚   â”œâ”€â”€ kafka_helper/       # Gestion des producteurs et consommateurs Kafka
â”‚   â”œâ”€â”€ dbConfig/           # Configuration de la base de donnÃ©es et modÃ¨les SQLAlchemy
â”‚   â”œâ”€â”€ utils/              # Outils divers (validation, logging, scheduling, etc.)
â”‚   â”œâ”€â”€ migrations/         # Scripts de migration Alembic
â”‚   â””â”€â”€ main.py             # Point d'entrÃ©e principal de l'application
â”œâ”€â”€ tests/                  # Tests unitaires
â””â”€â”€ data/                   # DonnÃ©es et logs
```

---

## ğŸš€ **Comment DÃ©marrer ?**

### 1. **PrÃ©requis**

- **Python 3.12+** ğŸ
- **Docker & Docker Compose** ğŸ³
- **PostgreSQL et Kafka**

### 2. **Installation**

1. **Clonez le dÃ©pÃ´t** :
   ```bash
   git clone https://github.com/sanlamamba/crypto_viz.git
   cd crypto_viz/data_flow
   ```

2. **CrÃ©ez un environnement virtuel et installez les dÃ©pendances** :
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```

3. **DÃ©marrez les services Docker** :
   ```bash
   docker-compose up -d
   ```

### 3. **ExÃ©cution**

- **Lancer le programme principal** :
   ```bash
   python src/main.py
   ```

---

## ğŸ” **Tests**

1. **Assurez-vous que les services sont en cours d'exÃ©cution** (Kafka, PostgreSQL).
2. **Lancez les tests unitaires avec pytest** :
   ```bash
   pytest tests/
   ```

---

## ğŸ³ **Services via Docker**

Ce projet utilise **Docker** pour simplifier l'instanciation des diffÃ©rents services nÃ©cessaires :

- **PostgreSQL** : Base de donnÃ©es pour stocker les donnÃ©es des cryptomonnaies.
- **Kafka** : UtilisÃ© pour la gestion des flux de donnÃ©es en temps rÃ©el.
- **Grafana** : Pour la visualisation et le suivi des donnÃ©es via des tableaux de bord.

Lancer tous ces services est aussi simple que d'exÃ©cuter :
```bash
docker-compose up -d
```
Cela assurera que tout est prÃªt et correctement configurÃ© pour commencer Ã  scraper et traiter les donnÃ©es. ğŸš€

---

## ğŸ¤ **Contribuer**

Les contributions sont les bienvenues ! Pour contribuer :

1. **Forkez le projet**.
2. **CrÃ©ez une branche pour vos modifications** :
   ```bash
   git checkout -b feature/ma-feature
   ```
3. **Faites vos commits** et soumettez une **Pull Request**.

Nous sommes ouverts aux idÃ©es et suggestions pour amÃ©liorer le projet. Chaque contribution compte ! ğŸ’ª

---

## ğŸ›¡ï¸ **SÃ©curitÃ© et Bonnes Pratiques**

- **Variables d'environnement** : Utilisez des variables d'environnement pour gÃ©rer les informations sensibles telles que les clÃ©s API et les mots de passe. Par exemple, crÃ©ez un fichier `.env` pour stocker ces informations et assurez-vous de l'ajouter au `.gitignore`.
- **Logs** : Le projet enregistre toutes les actions importantes, facilitant ainsi la dÃ©tection des problÃ¨mes. Les logs sont configurÃ©s via `logging_config.py` et sont enregistrÃ©s dans le dossier `data/logs`.
- **Tests** : Toujours ajouter des tests pour tout nouveau code Ã©crit, afin de garantir la qualitÃ© et la stabilitÃ© du projet.
- **Bonnes pratiques pour Docker** : Veillez Ã  limiter les permissions des conteneurs Docker et Ã  surveiller les images utilisÃ©es afin de minimiser les risques de sÃ©curitÃ©.

---

## âš™ï¸ **DÃ©tails Techniques et Architecture**

- **Scrapers** : Les scrapers pour **CoinGecko** et **CoinMarketCap** sont dÃ©veloppÃ©s avec **BeautifulSoup** et **requests**, permettant une extraction fiable des donnÃ©es en temps rÃ©el.
  - **Scrape Coingecko** : Utilise un soup pour naviguer dans les tables HTML afin d'extraire les noms, les prix, les capitalisations des cryptomonnaies et plus encore.
  - **Scrape CoinMarketCap** : Utilise un sÃ©lecteur CSS avec **BeautifulSoup** pour extraire les donnÃ©es pertinentes avec des sÃ©lecteurs personnalisÃ©s.

- **Kafka Integration** : Le systÃ¨me est basÃ© sur une architecture Ã  Ã©vÃ©nements utilisant **Kafka**.
  - **Producteur Kafka** : Normalise les donnÃ©es et les envoie vers le topic Kafka `crypto_viz`.
  - **Consommateur Kafka** : RÃ©cupÃ¨re les messages pour les traiter et les stocker dans la base de donnÃ©es.
  - Kafka est configurÃ© pour fonctionner avec un broker accessible en local via Docker, facilitant le dÃ©veloppement.

- **Base de DonnÃ©es** : La base de donnÃ©es **PostgreSQL** est structurÃ©e pour sÃ©parer les donnÃ©es actuelles et historiques des cryptomonnaies.

| ModÃ¨le                  | Description                                                                                     |
|-------------------------|-------------------------------------------------------------------------------------------------|
| **currencies**          | Contient les informations statiques des cryptomonnaies (nom, symbole).                         |
| **currency_data**       | Stocke les donnÃ©es en temps rÃ©el (prix actuel, capitalisation).                                |
| **currency_data_history** | Archive les donnÃ©es historiques, assurant une traÃ§abilitÃ© des variations des cryptomonnaies.    |

  - Les donnÃ©es sont mises Ã  jour toutes les minutes, les anciennes valeurs Ã©tant archivÃ©es dans la table `currency_data_history`.

- **Migrations Alembic** : Les changements de structure de base de donnÃ©es sont gÃ©rÃ©s avec **Alembic**.
  - Cela permet de suivre et d'appliquer des mises Ã  jour de schÃ©ma de base de donnÃ©es de maniÃ¨re ordonnÃ©e et collaborative.
  - Les fichiers de migration sont bien organisÃ©s, permettant d'historier les changements.

- **Normalisation des DonnÃ©es** : La classe `DataNormalizer` permet de regrouper les donnÃ©es collectÃ©es, de rÃ©soudre les conflits potentiels et de normaliser le format final avant l'insertion en base.
  - **RÃ©solution des Conflits** : Utilise des stratÃ©gies telles que le choix de la valeur majoritaire ou celle avec le meilleur facteur de confiance.
  - **Formatage StandardisÃ©** : Le format final inclut des informations telles que le nom, le prix, la source, et le facteur de confiance pour garantir la cohÃ©rence des donnÃ©es.

- **Multithreading** : Le module `threading` est utilisÃ© pour exÃ©cuter des tÃ¢ches comme le scraping et la consommation Kafka de maniÃ¨re concurrente.
  - Cela augmente l'efficacitÃ© du processus en utilisant plusieurs threads pour exÃ©cuter les tÃ¢ches parallÃ¨lement.
  - Le script `threading.py` encapsule la logique pour faciliter l'utilisation des threads dans le projet.

- **Planification des TÃ¢ches** : Le **scheduler** intÃ©grÃ© Ã  l'aide de la bibliothÃ¨que `schedule` permet de dÃ©finir des intervalles rÃ©guliers pour la collecte des donnÃ©es.
  - Le programme principal est configurÃ© pour exÃ©cuter un scraping des donnÃ©es toutes les minutes.
  - Les tÃ¢ches planifiÃ©es sont gÃ©rÃ©es de maniÃ¨re Ã  garantir une collecte continue sans interruption.

- **Flux de DonnÃ©es** :
  - **Scraping** : Le processus de scraping est exÃ©cutÃ© toutes les minutes, extrayant les donnÃ©es depuis CoinGecko et CoinMarketCap.
  - **Normalisation** : Les donnÃ©es sont ensuite normalisÃ©es pour Ã©viter les conflits et garantir la qualitÃ© des donnÃ©es.
  - **Production Kafka** : Une fois les donnÃ©es prÃªtes, elles sont envoyÃ©es dans un topic Kafka via un producteur Kafka.
  - **Consommation et Stockage** : Un consommateur Kafka rÃ©cupÃ¨re les donnÃ©es, les traite et les stocke dans la base de donnÃ©es PostgreSQL, en les archivant si nÃ©cessaire.

- **Producteur et Consommateur** :
  - **Producteur** : Le producteur Kafka, dÃ©fini dans `kafka_helper/producer.py`, envoie les donnÃ©es normalisÃ©es dans le topic Kafka `crypto_viz`.
  - **Consommateur** : Le consommateur, dÃ©fini dans `kafka_helper/consumer.py`, Ã©coute ce topic, traite les messages entrants et les insÃ¨re dans la base de donnÃ©es. La fonction `process_data` est utilisÃ©e pour gÃ©rer le traitement des donnÃ©es avant l'insertion.

---

## ğŸ“§ **Contact**

Pour toute question, suggestion ou simplement pour dire bonjour, contactez-nous via [GitHub](https://github.com/sanlamamba). Nous serions ravis d'Ã©changer avec vous ! ğŸ˜Š

Merci d'avoir choisi **CryptoViz** pour explorer le monde des cryptomonnaies. Nous espÃ©rons que ce projet vous aidera Ã  comprendre et analyser l'univers fascinant des cryptos d'une maniÃ¨re simple et efficace. ğŸš€

---

âœ¨ **Bon Scraping !** âœ¨

